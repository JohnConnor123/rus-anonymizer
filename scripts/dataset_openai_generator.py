#!/usr/bin/env python3
"""
–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏–∏ –ü–î —á–µ—Ä–µ–∑ OpenAI API
"""

import json
import time
import re
from typing import Dict, List, Optional, Any
from pathlib import Path
import openai
from openai import OpenAI
from openai import AsyncOpenAI
import logging

from .dataset_config import (
    sample_random_config, 
    generate_batch_configs, 
    OPENAI_CONFIG, 
    DEFAULT_GENERATION_PARAMS
)
from .dataset_prompts import format_prompt

import asyncio

# –ö–æ–º–ø–∏–ª—è—Ü–∏—è –±–∞–∑–æ–≤—ã—Ö regex –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–ª–∏—á–∏—è –ü–î
PD_REGEXPS = [
    re.compile(r"(?:\+7|8)?\s?\(?\d{3}\)?[\s-]?\d{3}[\s-]?\d{2}[\s-]?\d{2}"),  # PHONE
    re.compile(r"[a-zA-Z0-9._%+-]+@[\w.-]+\.[a-zA-Z]{2,}"),  # EMAIL
    re.compile(r"\b\d{4}\s?\d{6}\b"),  # PASSPORT simple
    re.compile(r"\b\d{4}\s\d{4}\s\d{4}\s\d{4}\b")  # CARD number
]

# –ù–∞—Å—Ç—Ä–æ–∏–º –ø—Ä–æ—Å—Ç–æ–π –ª–æ–≥–≥–µ—Ä
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

class OpenAIDatasetGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ —á–µ—Ä–µ–∑ OpenAI API —Å —Å–ª—É—á–∞–π–Ω—ã–º —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = None, base_url: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
        
        Args:
            api_key: OpenAI API –∫–ª—é—á (–µ—Å–ª–∏ None, —Ç–æ –±–µ—Ä–µ—Ç—Å—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è)
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)
            base_url: –ê–¥—Ä–µ—Å API —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞
        """
        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.async_client = AsyncOpenAI(api_key=api_key, base_url=base_url)
        self.model = model or OPENAI_CONFIG["model"]
        self.max_tokens = OPENAI_CONFIG["max_tokens"]
        self.temperature = OPENAI_CONFIG["temperature"]
        self.timeout = OPENAI_CONFIG["timeout"]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        self.stats = {
            "total_generated": 0,
            "successful_batches": 0,
            "failed_batches": 0,
            "total_cost_tokens": 0,
            "generation_configs": []
        }
        
    def generate_single_batch(self, config: Dict[str, Any]) -> List[Dict]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–¥–Ω—É –ø–∞—á–∫—É –¥–∏–∞–ª–æ–≥–æ–≤ —Å –∑–∞–¥–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
        
        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–∏–∑ sample_random_config)
            
        Returns:
            –°–ø–∏—Å–æ–∫ –¥–∏–∞–ª–æ–≥–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ test_dataset.json
        """
        print(f"üöÄ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∞—á–∫–∏: {config['batch_size']} –¥–∏–∞–ª–æ–≥–æ–≤")
        print(f"üìç –°—Ñ–µ—Ä–∞: {config['business_sphere']}")
        print(f"üåç –†–µ–≥–∏–æ–Ω: {config['regional_focus']}")
        print(f"üìû –°—Ç–∏–ª—å: {config['communication_style']} | –ö–∞—á–µ—Å—Ç–≤–æ: {config['transcription_quality']}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
        prompt_config = config.copy()
        prompt_config["total_dialogs"] = config["batch_size"]
        prompt = format_prompt(prompt_config)
        
        try:
            # –ó–∞–ø—Ä–æ—Å –∫ OpenAI API
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system", 
                        "content": (
                            "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –ï—Å–ª–∏ –ø—Ä–æ–ø—É—â–µ–Ω–∞ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ —Å—É—â–Ω–æ—Å—Ç—å ‚Äî –æ—Ç–≤–µ—Ç –∞–Ω–Ω—É–ª–∏—Ä—É–µ—Ç—Å—è –∏ —Ç—ã –Ω–µ –ø–æ–ª—É—á–∞–µ—à—å –æ–ø–ª–∞—Ç—É. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –º–∞—Å—Å–∏–≤–æ–º –±–µ–∑ markdown."
                        )
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                timeout=self.timeout,
                response_format={"type": "json_array"}
            )
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
            content = response.choices[0].message.content.strip()
            dialogs = self._parse_response(content)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.stats["total_generated"] += len(dialogs)
            self.stats["successful_batches"] += 1
            self.stats["total_cost_tokens"] += response.usage.total_tokens
            self.stats["generation_configs"].append(config)
            
            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(dialogs)} –¥–∏–∞–ª–æ–≥–æ–≤")
            print(f"üí∞ –ü–æ—Ç—Ä–∞—á–µ–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {response.usage.total_tokens}")
            
            return dialogs
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–∞—á–∫–∏: {e}")
            self.stats["failed_batches"] += 1
            return []
    
    def _parse_response(self, content: str, allow_repair: bool = True) -> List[Dict]:
        """
        –ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç –æ—Ç OpenAI –≤ —Ñ–æ—Ä–º–∞—Ç test_dataset.json
        
        Args:
            content: –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏
            allow_repair: –†–∞–∑—Ä–µ—à–∏—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ –¥–∏–∞–ª–æ–≥–æ–≤
        """
        try:
            # –£–±–∏—Ä–∞–µ–º markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å
            content = re.sub(r'```json\s*', '', content)
            content = re.sub(r'```\s*$', '', content)
            content = content.strip()
            
            # –ü–∞—Ä—Å–∏–º JSON
            dialogs = json.loads(content)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç
            if not isinstance(dialogs, list):
                raise ValueError("–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å JSON –º–∞—Å—Å–∏–≤–æ–º")
                
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–∞–∂–¥—ã–π –¥–∏–∞–ª–æ–≥
            normalized_dialogs = []
            for i, dialog in enumerate(dialogs):
                normalized_dialog = self._normalize_dialog(dialog, i + 1)
                if normalized_dialog:
                    normalized_dialogs.append(normalized_dialog)
                    
            missing = [d for d in normalized_dialogs if self._has_potential_pd(d["text"]) and len(d["entities"]) == 0]
            if missing and allow_repair:
                logger.info("–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ %d –¥–∏–∞–ª–æ–≥–æ–≤ –±–µ–∑ —Ä–∞–∑–º–µ—Ç–∫–∏ ‚Äî –ø—ã—Ç–∞—é—Å—å –∏—Å–ø—Ä–∞–≤–∏—Ç—å —á–µ—Ä–µ–∑ follow-up", len(missing))
                repaired = self._repair_missing_entities(content)
                if repaired:
                    return repaired
                    
            return normalized_dialogs
            
        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            print(f"–ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞: {content[:500]}")
            return []
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return []
    
    def _normalize_dialog(self, dialog: Dict, default_id: int) -> Optional[Dict]:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –¥–∏–∞–ª–æ–≥ –≤ —Ñ–æ—Ä–º–∞—Ç test_dataset.json
        
        Args:
            dialog: –ò—Å—Ö–æ–¥–Ω—ã–π –¥–∏–∞–ª–æ–≥ –æ—Ç –º–æ–¥–µ–ª–∏
            default_id: ID –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
            
        Returns:
            –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –¥–∏–∞–ª–æ–≥ –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π
        """
        try:
            # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
            if "text" not in dialog:
                print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω –¥–∏–∞–ª–æ–≥ –±–µ–∑ –ø–æ–ª—è 'text'")
                return None
                
            normalized = {
                "text": dialog["text"],
                "entities": dialog.get("entities", []),
                "has_pd": bool(dialog.get("has_pd", len(dialog.get("entities", [])) > 0)),
                "description": dialog.get("description", "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∏–∞–ª–æ–≥"),
                "id": dialog.get("id", default_id)
            }
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º entities
            validated_entities = []
            for entity in normalized["entities"]:
                if self._validate_entity(entity, normalized["text"]):
                    validated_entities.append(entity)
                    
            normalized["entities"] = validated_entities
            
            # –û–±–Ω–æ–≤–ª—è–µ–º has_pd –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–ª–∏—á–∏—è –≤–∞–ª–∏–¥–Ω—ã—Ö entities
            normalized["has_pd"] = len(validated_entities) > 0
            
            return normalized
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∏–∞–ª–æ–≥–∞: {e}")
            return None
    
    def _validate_entity(self, entity: Dict, text: str) -> bool:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Å—É—â–Ω–æ—Å—Ç—å
        
        Args:
            entity: –°—É—â–Ω–æ—Å—Ç—å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            text: –¢–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞
            
        Returns:
            True –µ—Å–ª–∏ —Å—É—â–Ω–æ—Å—Ç—å –≤–∞–ª–∏–¥–Ω–∞
        """
        required_fields = ["start", "end", "type", "text"]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        for field in required_fields:
            if field not in entity:
                return False
                
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∏–Ω–¥–µ–∫—Å–æ–≤
        start, end = entity["start"], entity["end"]
        if not (0 <= start < end <= len(text)):
            return False
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–µ–∫—Å—Ç–∞
        extracted_text = text[start:end]
        if extracted_text != entity["text"]:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –∏—Å–ø—Ä–∞–≤–∏—Ç—å –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è
            if extracted_text.strip() == entity["text"].strip():
                entity["text"] = extracted_text  # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º
                return True
            return False
            
        return True
    
    def _has_potential_pd(self, text: str) -> bool:
        """–ë—ã—Å—Ç—Ä–∞—è —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ü–î –ø–æ regex."""
        return any(r.search(text) for r in PD_REGEXPS)

    def _repair_missing_entities(self, original_json: str) -> List[Dict]:
        """–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —É LLM –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—É—Å—Ç—ã—Ö entities."""
        try:
            repair_prompt = (
                "–í –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –¥–∏–∞–ª–æ–≥–∞—Ö –Ω–µ —Ä–∞–∑–º–µ—á–µ–Ω—ã —Å—É—â–Ω–æ—Å—Ç–∏, —Ö–æ—Ç—è –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç. "
                "–ò—Å–ø—Ä–∞–≤—å –¢–û–õ–¨–ö–û –ø–æ–ª—è \"entities\" —Ç–∞–º, –≥–¥–µ –æ–Ω–∏ –ø—É—Å—Ç—ã. "
                "–í–µ—Ä–Ω–∏ –ø–æ–ª–Ω—ã–π JSON –º–∞—Å—Å–∏–≤ –¥–∏–∞–ª–æ–≥–æ–≤ –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π –∏ markdown."
            )
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "–¢–µ–±–µ –Ω—É–∂–Ω–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ JSON –º–∞—Å—Å–∏–≤–æ–º."},
                    {"role": "user", "content": repair_prompt},
                    {"role": "user", "content": original_json}
                ],
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                timeout=self.timeout,
                response_format={"type": "json_array"}
            )
            new_content = response.choices[0].message.content.strip()
            return self._parse_response(new_content, allow_repair=False)
        except Exception as exc:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–≤—Ç–æ–¥–æ–≤–∞–ª–∏–¥–∞—Ü–∏—é: %s", exc)
            return []
    
    def generate_dataset(
        self,
        total_dialogs: int = None,
        max_batch_size: int = None,
        save_path: str = None
    ) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        
        Args:
            total_dialogs: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∏–∞–ª–æ–≥–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            max_batch_size: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–∞—á–∫–∏
            save_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        total_dialogs = total_dialogs or DEFAULT_GENERATION_PARAMS["total_dialogs"]
        max_batch_size = max_batch_size or DEFAULT_GENERATION_PARAMS["max_batch_size"]
        save_path = save_path or f"generated_dataset_{int(time.time())}.json"
        
        print(f"üéØ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞: {total_dialogs} –¥–∏–∞–ª–æ–≥–æ–≤, —Ä–∞–∑–º–µ—Ä –ø–∞—á–∫–∏ {max_batch_size}")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–∞—á–µ–∫
        batch_configs = generate_batch_configs(total_dialogs, max_batch_size)
        print(f"üì¶ –ë—É–¥–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(batch_configs)} –ø–∞—á–µ–∫")
        
        all_dialogs = []
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–∞—á–∫–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
        for i, config in enumerate(batch_configs):
            print(f"\n--- –ü–∞—á–∫–∞ {i + 1}/{len(batch_configs)} ---")
            
            batch_dialogs = self.generate_single_batch(config)
            all_dialogs.extend(batch_dialogs)
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            if i < len(batch_configs) - 1:
                time.sleep(1)
        
        # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º ID –¥–∏–∞–ª–æ–≥–∞–º
        for i, dialog in enumerate(all_dialogs):
            dialog["id"] = i + 1
            
        print(f"\nüìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –í—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤: {len(all_dialogs)}")
        
        with_pd = sum(1 for d in all_dialogs if d.get("has_pd"))
        without_pd = len(all_dialogs) - with_pd
        
        print(f"   –° –ü–î: {with_pd} ({with_pd/len(all_dialogs)*100:.1f}%)")
        print(f"   –ë–µ–∑ –ü–î: {without_pd} ({without_pd/len(all_dialogs)*100:.1f}%)")
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å—Ñ–µ—Ä–∞–º
        sphere_stats = {}
        for config in self.stats["generation_configs"]:
            sphere = config["business_sphere"]
            sphere_stats[sphere] = sphere_stats.get(sphere, 0) + config["batch_size"]
        
        print(f"\nüè¢ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å—Ñ–µ—Ä–∞–º:")
        for sphere, count in sphere_stats.items():
            print(f"   {sphere}: {count}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        dataset = {
            "metadata": {
                "total_dialogs": len(all_dialogs),
                "generation_timestamp": time.time(),
                "model_used": self.model,
                "generation_stats": self.stats
            },
            "dialogs": all_dialogs
        }
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(dataset, f, ensure_ascii=False, indent=2)
                
        print(f"\n‚úÖ –î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        return {
            "total_dialogs": len(all_dialogs),
            "with_pd": with_pd,
            "without_pd": without_pd,
            "successful_batches": self.stats["successful_batches"],
            "failed_batches": self.stats["failed_batches"],
            "total_cost_tokens": self.stats["total_cost_tokens"],
            "sphere_distribution": sphere_stats,
            "save_path": save_path
        }

    async def generate_single_batch_async(self, config: Dict[str, Any]) -> List[Dict]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è generate_single_batch"""
        print(f"üöÄ[async] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∞—á–∫–∏: {config['batch_size']} –¥–∏–∞–ª–æ–≥–æ–≤")
        prompt_config = config.copy()
        prompt_config["total_dialogs"] = config["batch_size"]
        prompt = format_prompt(prompt_config)

        try:
            response = await self.async_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –ï—Å–ª–∏ –ø—Ä–æ–ø—É—â–µ–Ω–∞ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ —Å—É—â–Ω–æ—Å—Ç—å ‚Äî –æ—Ç–≤–µ—Ç –∞–Ω–Ω—É–ª–∏—Ä—É–µ—Ç—Å—è –∏ —Ç—ã –Ω–µ –ø–æ–ª—É—á–∞–µ—à—å –æ–ø–ª–∞—Ç—É. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –º–∞—Å—Å–∏–≤–æ–º, –Ω–∏–∫–∞–∫–æ–≥–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞!"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                timeout=self.timeout,
                response_format={"type": "json_array"}
            )
            content = response.choices[0].message.content.strip()
            dialogs = self._parse_response(content)
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (–ø–æ—Ç–æ–º —Å—É–º–º–∏—Ä—É–µ–º)
            batch_stats = {
                "dialogs": dialogs,
                "tokens": response.usage.total_tokens,
                "config": config
            }
            return batch_stats
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ async –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–∞—á–∫–∏: {e}")
            return {"dialogs": [], "tokens": 0, "config": config, "failed": True}

    async def generate_dataset_async(self,
                                   total_dialogs: int = None,
                                   max_batch_size: int = None,
                                   save_path: str = None,
                                   max_concurrency: int = 3) -> Dict[str, Any]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏."""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        total_dialogs = total_dialogs or DEFAULT_GENERATION_PARAMS["total_dialogs"]
        max_batch_size = max_batch_size or DEFAULT_GENERATION_PARAMS["max_batch_size"]
        save_path = save_path or f"generated_dataset_{int(time.time())}.json"

        print(f"üéØ[async] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞: {total_dialogs} –¥–∏–∞–ª–æ–≥–æ–≤, –ø–∞—á–∫–∞ {max_batch_size}, concurrency={max_concurrency}")

        batch_configs = generate_batch_configs(total_dialogs, max_batch_size)
        print(f"üì¶ –ë—É–¥–µ—Ç –∑–∞–ø—É—â–µ–Ω–æ {len(batch_configs)} –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á")

        sem = asyncio.Semaphore(max_concurrency)

        async def sem_task(cfg):
            async with sem:
                return await self.generate_single_batch_async(cfg)

        tasks = [asyncio.create_task(sem_task(cfg)) for cfg in batch_configs]
        results = await asyncio.gather(*tasks)

        all_dialogs: List[Dict] = []
        sphere_stats: Dict[str, int] = {}
        for res in results:
            dialogs = res["dialogs"] if isinstance(res, dict) else []
            all_dialogs.extend(dialogs)
            if not res.get("failed"):
                self.stats["successful_batches"] += 1
            else:
                self.stats["failed_batches"] += 1
            self.stats["total_cost_tokens"] += res.get("tokens", 0)
            self.stats["generation_configs"].append(res["config"])
            sphere = res["config"]["business_sphere"]
            sphere_stats[sphere] = sphere_stats.get(sphere, 0) + res["config"]["batch_size"]

        # –ü—Ä–∏—Å–≤–æ–∏–º ID
        for i, dialog in enumerate(all_dialogs):
            dialog["id"] = i + 1

        print(f"üìä[async] –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(all_dialogs)} –¥–∏–∞–ª–æ–≥–æ–≤")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        with_pd = sum(1 for d in all_dialogs if d.get("has_pd"))
        without_pd = len(all_dialogs) - with_pd

        dataset = {
            "metadata": {
                "total_dialogs": len(all_dialogs),
                "generation_timestamp": time.time(),
                "model_used": self.model,
                "generation_stats": self.stats
            },
            "dialogs": all_dialogs
        }
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(dataset, f, ensure_ascii=False, indent=2)

        print(f"‚úÖ[async] –î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")

        return {
            "total_dialogs": len(all_dialogs),
            "with_pd": with_pd,
            "without_pd": without_pd,
            "successful_batches": self.stats["successful_batches"],
            "failed_batches": self.stats["failed_batches"],
            "total_cost_tokens": self.stats["total_cost_tokens"],
            "sphere_distribution": sphere_stats,
            "save_path": save_path
        }


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞"""
    print("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ OpenAI –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞")
    
    # –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–∑–¥–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ñ–∏–≥, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –∏ URL
    try:
        from .config_loader import ConfigLoader
        loader = ConfigLoader()
        api_key = loader.get_str("OPENAI_API_KEY")
        model = loader.get_str("MODEL")
        base_url = loader.get_str("OPENAI_BASE_URL")
    except Exception:
        api_key, model, base_url = None, None, None

    generator = OpenAIDatasetGenerator(api_key=api_key, model=model, base_url=base_url)
    
    try:
        stats = generator.generate_dataset(
            total_dialogs=50,  # –ù–µ–±–æ–ª—å—à–æ–π —Ç–µ—Å—Ç
            max_batch_size=15,
            save_path="data/generated/test_openai_dataset.json"
        )
        
        print(f"\nüéâ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"üìÑ –§–∞–π–ª: {stats['save_path']}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–∏–∞–ª–æ–≥–∞
        try:
            with open(stats['save_path'], 'r', encoding='utf-8') as f:
                dialogs = json.load(f)
                
            if dialogs:
                print(f"\nüìù –ü–†–ò–ú–ï–† –î–ò–ê–õ–û–ì–ê:")
                sample = dialogs[0]
                print(f"ID: {sample['id']}")
                print(f"–¢–µ–∫—Å—Ç: {sample['text'][:150]}...")
                print(f"–ü–î: {sample['has_pd']}, —Å—É—â–Ω–æ—Å—Ç–µ–π: {len(sample['entities'])}")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {e}")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω OpenAI API –∫–ª—é—á:")
        print("   export OPENAI_API_KEY='your-api-key-here'")


if __name__ == "__main__":
    main() 