#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ llama-4-maverick-2.json
–ù–∞—Ö–æ–¥–∏—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –∏—Ö –≤ entities
"""

import json
import re
from typing import List, Dict, Tuple, Any
from pathlib import Path

# –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –ü–î
PD_PATTERNS = {
    'PHONE': [
        re.compile(r"(?:\+7|8)?\s?\(?\d{3}\)?[\s-]?\d{3}[\s-]?\d{2}[\s-]?\d{2}"),
        re.compile(r"8\s?\d{3}\s?\d{3}\s?\d{2}\s?\d{2}"),
        re.compile(r"\+7\s?\d{3}\s?\d{3}\s?\d{2}\s?\d{2}")
    ],
    'EMAIL': [
        re.compile(r"[a-zA-Z0-9._%+-]+@[\w.-]+\.[a-zA-Z]{2,}")
    ],
    'PERSON': [
        re.compile(r"(?:–º–µ–Ω—è –∑–æ–≤—É—Ç|–∑–æ–≤—É—Ç –º–µ–Ω—è|–º–æ—ë –∏–º—è|–º–æ–µ –∏–º—è)\s+([–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å][–∞-—è—ë]+)*)", re.IGNORECASE),
        re.compile(r"([–ê-–Ø–Å][–∞-—è—ë]+\s+[–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å][–∞-—è—ë]+)?)\s+(?:–∑–≤–æ–Ω–∏—Ç|–∑–≤–æ–Ω—é|–æ–±—Ä–∞—â–∞–µ—Ç—Å—è)", re.IGNORECASE)
    ],
    'PASSPORT': [
        re.compile(r"\b\d{4}\s?\d{6}\b"),
        re.compile(r"–ø–∞—Å–ø–æ—Ä—Ç\s*:?\s*(\d{4}\s?\d{6})", re.IGNORECASE)
    ],
    'SNILS': [
        re.compile(r"\b\d{3}[-\s]?\d{3}[-\s]?\d{3}[-\s]?\d{2}\b"),
        re.compile(r"–°–ù–ò–õ–°\s*:?\s*(\d{3}[-\s]?\d{3}[-\s]?\d{3}[-\s]?\d{2})", re.IGNORECASE)
    ],
    'INN': [
        re.compile(r"\b\d{10,12}\b"),
        re.compile(r"–ò–ù–ù\s*:?\s*(\d{10,12})", re.IGNORECASE)
    ],
    'CARD_NUMBER': [
        re.compile(r"\b\d{4}\s\d{4}\s\d{4}\s\d{4}\b"),
        re.compile(r"–∫–∞—Ä—Ç[–∞—ã]\s*:?\s*(\d{4}\s\d{4}\s\d{4}\s\d{4})", re.IGNORECASE)
    ],
    'VIN_NUMBER': [
        re.compile(r"\b[A-HJ-NPR-Z0-9]{17}\b"),
        re.compile(r"VIN\s*:?\s*([A-HJ-NPR-Z0-9]{17})", re.IGNORECASE)
    ],
    'BANK_ACCOUNT': [
        re.compile(r"\b\d{20}\b"),
        re.compile(r"—Ä–∞—Å—á–µ—Ç–Ω—ã–π —Å—á–µ—Ç\s*:?\s*(\d{20})", re.IGNORECASE)
    ]
}

def find_entities_in_text(text: str) -> List[Dict[str, Any]]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ —Å—É—â–Ω–æ—Å—Ç–∏ –≤ —Ç–µ–∫—Å—Ç–µ —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π
    """
    entities = []
    
    for entity_type, patterns in PD_PATTERNS.items():
        for pattern in patterns:
            matches = pattern.finditer(text)
            
            for match in matches:
                # –î–ª—è –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö –≥—Ä—É–ø–ø –±–µ—Ä–µ–º –≥—Ä—É–ø–ø—É 1, –∏–Ω–∞—á–µ –≤—Å—ë —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                if match.groups():
                    entity_text = match.group(1)
                    start = match.start(1)
                    end = match.end(1)
                else:
                    entity_text = match.group(0)
                    start = match.start()
                    end = match.end()
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
                if validate_entity(entity_type, entity_text):
                    entities.append({
                        'start': start,
                        'end': end,
                        'type': entity_type,
                        'text': entity_text
                    })
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã (–æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –ø–æ–∑–∏—Ü–∏–∏)
    unique_entities = []
    seen_positions = set()
    
    for entity in entities:
        pos_key = (entity['start'], entity['end'])
        if pos_key not in seen_positions:
            unique_entities.append(entity)
            seen_positions.add(pos_key)
    
    return unique_entities

def validate_entity(entity_type: str, text: str) -> bool:
    """
    –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π
    
    Args:
        entity_type: –¢–∏–ø —Å—É—â–Ω–æ—Å—Ç–∏
        text: –¢–µ–∫—Å—Ç —Å—É—â–Ω–æ—Å—Ç–∏
        
    Returns:
        True –µ—Å–ª–∏ —Å—É—â–Ω–æ—Å—Ç—å –≤–∞–ª–∏–¥–Ω–∞
    """
    text = text.strip()
    
    if entity_type == 'PHONE':
        # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –Ω–µ—Ü–∏—Ñ—Ä–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
        digits = re.sub(r'\D', '', text)
        return len(digits) in [10, 11] and digits.isdigit()
    
    elif entity_type == 'EMAIL':
        # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ email
        return '@' in text and '.' in text.split('@')[1]
    
    elif entity_type == 'PERSON':
        # –ò–º—è –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã –∏ –ø—Ä–æ–±–µ–ª—ã
        return re.match(r'^[–ê-–Ø–Å–∞-—è—ë\s]+$', text) and len(text.split()) >= 1
    
    elif entity_type == 'PASSPORT':
        # –ü–∞—Å–ø–æ—Ä—Ç: 4 —Ü–∏—Ñ—Ä—ã + 6 —Ü–∏—Ñ—Ä
        digits = re.sub(r'\D', '', text)
        return len(digits) == 10 and digits.isdigit()
    
    elif entity_type == 'SNILS':
        # –°–ù–ò–õ–°: 11 —Ü–∏—Ñ—Ä
        digits = re.sub(r'\D', '', text)
        return len(digits) == 11 and digits.isdigit()
    
    elif entity_type == 'INN':
        # –ò–ù–ù: 10 –∏–ª–∏ 12 —Ü–∏—Ñ—Ä
        return len(text) in [10, 12] and text.isdigit()
    
    elif entity_type == 'CARD_NUMBER':
        # –ù–æ–º–µ—Ä –∫–∞—Ä—Ç—ã: 16 —Ü–∏—Ñ—Ä
        digits = re.sub(r'\D', '', text)
        return len(digits) == 16 and digits.isdigit()
    
    elif entity_type == 'VIN_NUMBER':
        # VIN: 17 —Å–∏–º–≤–æ–ª–æ–≤, –∏—Å–∫–ª—é—á–∞—è I, O, Q
        return len(text) == 17 and not any(c in text for c in 'IOQ')
    
    elif entity_type == 'BANK_ACCOUNT':
        # –†–∞—Å—á–µ—Ç–Ω—ã–π —Å—á–µ—Ç: 20 —Ü–∏—Ñ—Ä
        return len(text) == 20 and text.isdigit()
    
    return True

def annotate_dataset(input_file: str, output_file: str) -> Dict[str, Any]:
    """
    –ê–Ω–Ω–æ—Ç–∏—Ä—É–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç, –¥–æ–±–∞–≤–ª—è—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏
    
    Args:
        input_file: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É
        output_file: –ü—É—Ç—å –∫ –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É
        
    Returns:
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
    """
    print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞: {input_file}")
    
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    dialogs = data.get('dialogs', [])
    print(f"üìã –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(dialogs)} –¥–∏–∞–ª–æ–≥–æ–≤")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = {
        'total_dialogs': len(dialogs),
        'originally_with_pd': sum(1 for d in dialogs if d['has_pd']),
        'originally_without_pd': sum(1 for d in dialogs if not d['has_pd']),
        'dialogs_updated': 0,
        'entities_added': 0,
        'entity_types_found': {}
    }
    
    # –ê–Ω–Ω–æ—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –¥–∏–∞–ª–æ–≥
    for dialog in dialogs:
        text = dialog['text']
        existing_entities = dialog.get('entities', [])
        
        # –ù–∞—Ö–æ–¥–∏–º –Ω–æ–≤—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏
        found_entities = find_entities_in_text(text)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏ —É–∂–µ –µ—Å—Ç—å
        existing_positions = {(e['start'], e['end']) for e in existing_entities}
        new_entities = [e for e in found_entities 
                       if (e['start'], e['end']) not in existing_positions]
        
        if new_entities:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏
            dialog['entities'].extend(new_entities)
            dialog['has_pd'] = True
            
            stats['dialogs_updated'] += 1
            stats['entities_added'] += len(new_entities)
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–∏–ø—ã —Å—É—â–Ω–æ—Å—Ç–µ–π
            for entity in new_entities:
                entity_type = entity['type']
                stats['entity_types_found'][entity_type] = (
                    stats['entity_types_found'].get(entity_type, 0) + 1
                )
            
            print(f"‚úÖ –î–∏–∞–ª–æ–≥ {dialog['id']}: –¥–æ–±–∞–≤–ª–µ–Ω–æ {len(new_entities)} —Å—É—â–Ω–æ—Å—Ç–µ–π")
            for entity in new_entities:
                print(f"   - {entity['type']}: '{entity['text']}'")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–∞—Ç–∞—Å–µ—Ç–∞
    stats['finally_with_pd'] = sum(1 for d in dialogs if d['has_pd'])
    stats['finally_without_pd'] = len(dialogs) - stats['finally_with_pd']
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
    data['metadata']['annotation_stats'] = stats
    data['metadata']['annotation_timestamp'] = __import__('time').time()
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ –ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
    
    return stats

def print_annotation_stats(stats: Dict[str, Any]):
    """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏"""
    print("\n" + "="*60)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–ù–ù–û–¢–ê–¶–ò–ò")
    print("="*60)
    
    print(f"üìã –í—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤: {stats['total_dialogs']}")
    print(f"üìù –û–±–Ω–æ–≤–ª–µ–Ω–æ –¥–∏–∞–ª–æ–≥–æ–≤: {stats['dialogs_updated']}")
    print(f"üÜï –î–æ–±–∞–≤–ª–µ–Ω–æ —Å—É—â–Ω–æ—Å—Ç–µ–π: {stats['entities_added']}")
    
    print(f"\nüìà –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ü–î:")
    print(f"   –ë—ã–ª–æ —Å –ü–î: {stats['originally_with_pd']} ({stats['originally_with_pd']/stats['total_dialogs']*100:.1f}%)")
    print(f"   –°—Ç–∞–ª–æ —Å –ü–î: {stats['finally_with_pd']} ({stats['finally_with_pd']/stats['total_dialogs']*100:.1f}%)")
    print(f"   –ü—Ä–∏—Ä–æ—Å—Ç: +{stats['finally_with_pd'] - stats['originally_with_pd']} –¥–∏–∞–ª–æ–≥–æ–≤")
    
    if stats['entity_types_found']:
        print(f"\nüîç –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–∏–ø—ã —Å—É—â–Ω–æ—Å—Ç–µ–π:")
        for entity_type, count in sorted(stats['entity_types_found'].items()):
            print(f"   {entity_type}: {count}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    input_file = "data/generated/llama-4-maverick-2.json"
    output_file = "data/generated/llama-4-maverick-2_annotated.json"
    
    if not Path(input_file).exists():
        print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return 1
    
    print("üöÄ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞")
    print("="*50)
    
    try:
        stats = annotate_dataset(input_file, output_file)
        print_annotation_stats(stats)
        
        print(f"\nüéâ –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìÑ –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª: {input_file}")
        print(f"üìÑ –ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª: {output_file}")
        
        return 0
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏: {e}")
        return 1

if __name__ == "__main__":
    exit(main()) 