# üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö - data_processor.py

## üìã –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

–°–∫—Ä–∏–ø—Ç `scripts/data_processor.py` –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–∏–∞–ª–æ–≥–æ–≤. –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤, —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏–∏.

## üõ†Ô∏è –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏

- –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –≤ –æ–¥–∏–Ω
- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
- –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ train/val
- –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
- –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ —Å—É—â–Ω–æ—Å—Ç–µ–π

## üì• –í—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

### –ö–æ–º–∞–Ω–¥–Ω–∞—è —Å—Ç—Ä–æ–∫–∞:
```bash
# –ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
python scripts/data_processor.py --input data/generated/dataset.json --analyze-only

# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
python scripts/data_processor.py --merge data/generated/*.json --output data/processed/merged.json

# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º –≤ –∫–∞–≤—ã—á–∫–∞—Ö
python scripts/data_processor.py --merge "data/generated/llama*.json" --output data/processed/filtered.json

# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
python scripts/data_processor.py --merge file1.json file2.json --output combined.json
```

### –ü—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å:
```python
from scripts.data_processor import DatasetProcessor

# –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ —Å —Ñ–∞–π–ª–∞–º–∏ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
processor = DatasetProcessor(
    input_files=["dataset1.json", "dataset2.json"],
    output_dir="data/processed"
)

# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ input_files)
merged_data = processor.merge_datasets()

# –ê–Ω–∞–ª–∏–∑ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
stats = processor.calculate_stats(merged_data.get('dialogs', []))
print(f"–í—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤: {stats.total_dialogs}")
print(f"–î–∏–∞–ª–æ–≥–æ–≤ —Å –ü–î: {stats.pd_dialogs} ({stats.pd_percentage:.1f}%)")

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val
train_data, val_data = processor.split_dataset(merged_data, train_ratio=0.7)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
processor.save_dataset(merged_data, "merged_dataset.json")
processor.save_dataset(train_data, "train_dataset.json")
processor.save_dataset(val_data, "val_dataset.json")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞–Ω–µ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
saved_data = processor.load_dataset("data/processed/merged_dataset.json")

### –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± - –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞:
```python
# –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞
processor = DatasetProcessor(input_files=[], output_dir="data/processed")
data = processor.load_dataset("existing_file.json")
stats = processor.calculate_stats(data.get('dialogs', []))
```

## üéØ –û–ø–µ—Ä–∞—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏

### 1. –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞:
- –ü–æ–¥—Å—á–µ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–∏–∞–ª–æ–≥–æ–≤
- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ –¥–∏–∞–ª–æ–≥–æ–≤ —Å –ü–î
- –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ —Å—É—â–Ω–æ—Å—Ç–µ–π
- –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—É—â–Ω–æ—Å—Ç–µ–π

### 2. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤:
```python
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
merged_metadata = {
    "total_dialogs": stats.total_dialogs,
    "merge_timestamp": datetime.now().timestamp(),
    "source_files": self.input_files,
    "merged_stats": {
        "total_dialogs": stats.total_dialogs,
        "pd_dialogs": stats.pd_dialogs,
        "pd_percentage": stats.pd_percentage,
        "total_entities": stats.total_entities,
        "entity_types": stats.entity_types,
        "total_cost_tokens": total_cost_tokens
    }
}
```

### 3. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val:
- –°–ª—É—á–∞–π–Ω–æ–µ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–æ–≤
- –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–º—É —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—é
- –ü–µ—Ä–µ—Å—á–µ—Ç ID –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–∞–±–æ—Ä–∞
- –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö

### 4. –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ:
- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º —Å—É—â–Ω–æ—Å—Ç–µ–π
- –ü—Ä–æ—Ü–µ–Ω—Ç –¥–∏–∞–ª–æ–≥–æ–≤ —Å –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
- –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
- –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º

## üì§ –í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞:
```
üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞: data/generated/dataset.json
–í—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤: 491
–î–∏–∞–ª–æ–≥–æ–≤ —Å –ü–î: 32 (6.5%)
–î–∏–∞–ª–æ–≥–æ–≤ –±–µ–∑ –ü–î: 459
–í—Å–µ–≥–æ —Å—É—â–Ω–æ—Å—Ç–µ–π: 34

–¢–∏–ø—ã —Å—É—â–Ω–æ—Å—Ç–µ–π:
  ADDRESS: 1
  PHONE: 13
  EMAIL: 5
  PERSON: 4
```

### –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç:
```json
{
  "metadata": {
    "total_dialogs": 3352,
    "merge_timestamp": 1750283188.0569782,
    "source_files": ["file1.json", "file2.json"],
    "merged_stats": {
      "total_dialogs": 3352,
      "pd_dialogs": 714,
      "pd_percentage": 21.3,
      "total_entities": 1200,
      "entity_types": {
        "PERSON": 400,
        "PHONE": 350,
        "EMAIL": 200
      },
      "total_cost_tokens": 101532
    }
  },
  "dialogs": [...]
}
```

## üîß –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

### –ö–ª–∞—Å—Å DatasetProcessor:
```python
class DatasetProcessor:
    def __init__(self, input_files: List[str], output_dir: str = "data/processed"):
        self.input_files = input_files
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
    
    def load_dataset(self, file_path: str) -> Dict[str, Any]
    def calculate_stats(self, dialogs: List[Dict[str, Any]]) -> DatasetStats
    def merge_datasets(self) -> Dict[str, Any]
    def split_dataset(self, data: Dict[str, Any], train_ratio: float = 0.7) -> Tuple[Dict[str, Any], Dict[str, Any]]
    def save_dataset(self, data: Dict[str, Any], filename: str)
    def process_all(self, train_ratio: float = 0.7, seed: int = 42)
```

### –ö–ª–∞—Å—Å DatasetStats:
```python
@dataclass
class DatasetStats:
    total_dialogs: int
    pd_dialogs: int
    non_pd_dialogs: int
    pd_percentage: float
    total_entities: int
    entity_types: Dict[str, int]
```

### –§—É–Ω–∫—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞:
- `analyze_dataset()` - –ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å –≤—ã–≤–æ–¥–æ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
- `main()` - –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏

## üì¶ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

```txt
json
random
pathlib
typing
dataclasses
logging
argparse
glob
datetime
```

## ‚ö†Ô∏è –ü—Ä–∏–º–µ—á–∞–Ω–∏—è

- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–æ–∫**: –°–æ–∑–¥–∞–µ—Ç –≤—ã—Ö–æ–¥–Ω—É—é –ø–∞–ø–∫—É –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
- **–ü–µ—Ä–µ—Å—á–µ—Ç ID**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç ID –¥–∏–∞–ª–æ–≥–æ–≤ –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
- **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ glob**: –†–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ —Å —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–º–∏ shell —Å–ø–∏—Å–∫–∞–º–∏, —Ç–∞–∫ –∏ —Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏
- **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞**: –ü–æ–¥—Ä–æ–±–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
- **–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ**: –ü–æ–¥—Ä–æ–±–Ω—ã–µ –ª–æ–≥–∏ –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π

## üîó –°–≤—è–∑–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã

- `scripts/merge_datasets.py` - –ü—Ä–æ—Å—Ç–æ–µ —Å–ª–∏—è–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
- `scripts/split_dataset.py` - –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
- `debug/test_pd_detection.py` - –¢–µ—Å—Ç—ã —Ñ—É–Ω–∫—Ü–∏–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ 